{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03b15f9-a846-409f-9768-c409d993cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# santander Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0a6f2-f427-432e-bf22-52d4ac8e8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "# import eli5\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pdpbox import pdp, info_plots\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, roc_curve, auc\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688467a7-cabf-4d7c-95a6-062547b2c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir(\"E:/JUPYTER/Data Science/Project 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0700c90-9fac-4f5b-a16d-4795b36e6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4a702-e8a6-445d-b1a3-9ed0f2d67a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the train dataset\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ad4e1-09b4-4482-8346-2be34b8a2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16755bc7-be80-45dd-8dfc-376d57367a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42227d3-2844-4fb6-bb13-c5425f2f0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the data\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d173f5c0-da38-4ac9-a899-fd7c8d655875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target class count\n",
    "target_class = df_train['target'].value_counts()\n",
    "print('COUNT OF THE TARGET CLASS :\\n', target_class)\n",
    "\n",
    "# percentage of the target class count\n",
    "per_target_class = df_train['target'].value_counts()/len(df_train)*100\n",
    "print('PERCENTAGE OF THE TARGET CLASS COUNT :\\n',per_target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dabbd3-e066-4552-9e3b-b57f5e36b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot & violin plot for target class\n",
    "fig,ax = plt.subplots(1, 2, figsize = (20,5))\n",
    "sns.countplot(df_train.target.values, ax = ax[0], palette = 'spring')\n",
    "sns.violinplot(x = df_train_target.values, y = df_train.index.values, ax = ax[1], palette = 'spring')\n",
    "sns.stripplot(x = df_train_target.values, y = df_train.index.values, jitter = True, color = 'black', linewidth = 0.5, size = 0.5, ax = ax[1], palette = 'spring')\n",
    "ax[0].set_xlabel('Target')\n",
    "ax[1].set_xlabel('Target')\n",
    "ax[1].set_ylabel('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15b63f-afcc-417c-a515-20bb8672ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "# we are having a unbalanced data, where 90% of the data isno. of customers who will make transaction & 10% of the data are those who will nit make a transaction.\n",
    "# from violin plots, it seems that there is no realation between the target and index of the dataframe, it is more dominated by zero compared to ones.\n",
    "# from jitter plots with violin plots, we can observe that target looks uniformly distributed over indexes of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895f0a5-884b-48d9-90a3-461a64b979f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the train attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0e24d-36f7-40de-b94e-dc5c2b7a3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Distribution of the train attributes\n",
    "\n",
    "def plot_train_attribute_distribution(t0, t1, label1, label2, train_attributes):\n",
    "    i = 0\n",
    "    sns.set_style('darkgrid')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplots(10, 10, figsize=(22,18))\n",
    "\n",
    "    for attribute in train_attributes:\n",
    "        i += 1\n",
    "        plt.subplot(10, 10, i)\n",
    "        sns.distplot(t0[attribute], hist = False, label = label1)\n",
    "        sns.distplot(t1[attribute], hist = False, label = label2)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Attribute',)\n",
    "        sns.set_style(\"ticks\", {\"xticks.major.size\" : 8, \"yticks.major.size\" : 8})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff53ad-12e1-4c84-a7cf-c30d22ad3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing first 100 train attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33f9f1-b08c-41ca-be02-7a22188c3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# corresponding to negative class\n",
    "t0 = df_train[df_train.target.values == 0]\n",
    "\n",
    "\n",
    "# corresponding to negative class\n",
    "t1 = df_train[df_train.target.values == 1]\n",
    "\n",
    "# train attributes from 2 to 102\n",
    "train_attributes = df_train.columns.values[2:102]\n",
    "\n",
    "# plot distribution of the train attribute\n",
    "plot_train_attribute_distribution(t0, t1, '0', '1', train_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1d950-b732-47fd-a1c7-7e9b1baab7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting next 100 train attributes\n",
    "\n",
    "# train attributes from 2 to 102\n",
    "train_attributes = df_train.columns.values[102:202]\n",
    "\n",
    "# plot distribution of the train attribute\n",
    "plot_train_attribute_distribution(t0, t1, '0', '1', train_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c0954-2717-4d00-a0c3-9992c95a3184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation : We can observe that there is a considerable number of features which have significantly different distribution. for eg var_0, var_1, var_6, var_109 etc.\n",
    "# there are also connsiderable number of features which have same distribution. for eg var_101, var_4, var_5 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2dd30-f7ff-4dd5-bce3-f9084796af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4763e-0cb5-4655-ac2c-d8bc1fc49479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086bab6-4bcf-4415-af81-5659bcb87727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfc47e-6f67-4818-a20e-3b783b742061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77255782-2410-4f0c-a6f2-3c447eb920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Distribution of test attributes\n",
    "\n",
    "def plot_test_attribute_distribution(test_attributes):\n",
    "    i = 0\n",
    "    sns.set_style('darkgrid')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplots(10, 10, figsize=(22,18))\n",
    "\n",
    "    for attribute in test_attributes:\n",
    "        i += 1\n",
    "        plt.subplot(10, 10, i)\n",
    "        sns.distplot(df_test[attribute], hist = False)\n",
    "        plt.xlabel('Attribute',)\n",
    "        sns.set_style(\"ticks\", {\"xticks.major.size\" : 8, \"yticks.major.size\" : 8})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd089df-5e5b-425f-a49b-45aef4305379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing first 100 test attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77055d-f82f-4dc4-87ac-ffca8b77c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test attributes from 1 to 101\n",
    "test_attributes = df_test.columns.values[1:101]\n",
    "\n",
    "# plot distribution of the test attribute\n",
    "plot_test_attribute_distribution(test_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bdfb4-cfcf-4a32-9069-d7f3326c9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting next 100 test attributes\n",
    "\n",
    "# train attributes from 2 to 102\n",
    "test_attributes = df_test.columns.values[102:202]\n",
    "\n",
    "# plot distribution of the train attribute\n",
    "plot_test_attribute_distribution(train_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90aa2a3-1cf9-4b10-9ae6-22968a0a9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of mean values per rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420d522-346f-4bb1-bec7-6a28cc5a9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Distribution of Mean Value per column in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# train attributes\n",
    "train_attributes = df_train.columns.values[2:202]\n",
    "\n",
    "# test attributes\n",
    "test_attributes = df_test.columns.values[1:201]\n",
    "\n",
    "# Distribution plot for mean values per column in train attributes\n",
    "sns.distplot(df_train[train_attributes].mean(axis = 0), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for mean values per column in test attributes\n",
    "sns.distplot(df_test[test_attributes].mean(axis = 0), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Mean Values per Column in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Mean Values per row in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Distribution plot for mean values per row in train attributes\n",
    "sns.distplot(df_train[train_attributes].mean(axis = 1), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for mean values per row in test attributes\n",
    "sns.distplot(df_test[test_attributes].mean(axis = 1), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Mean Values per Row in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb150923-7800-44d4-8c4d-4c51d0aa2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Standard Deviation Values per rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a651d-58be-498b-8708-4f910dbddd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Distribution of Standard Deviation per column in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# train attributes\n",
    "train_attributes = df_train.columns.values[2:202]\n",
    "\n",
    "# test attributes\n",
    "test_attributes = df_test.columns.values[1:201]\n",
    "\n",
    "# Distribution plot for S.D. values per column in train attributes\n",
    "sns.distplot(df_train[train_attributes].std(axis = 0), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for S.D. values per column in test attributes\n",
    "sns.distplot(df_test[test_attributes].std(axis = 0), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Standard Deviation Values per Column in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of S.D. Values per row in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Distribution plot for S.D. values per row in train attributes\n",
    "sns.distplot(df_train[train_attributes].std(axis = 1), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for S.D. values per row in test attributes\n",
    "sns.distplot(df_test[test_attributes].std(axis = 1), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Standard Deviation Values per Row in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52ebd8-4d6d-47ac-8720-7e33476c2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsitribution of Kurtosis Values per Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e8eef-aad5-46e7-9ac1-c90e8ca90953",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Distribution of Kurtosis per column in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# train attributes\n",
    "train_attributes = df_train.columns.values[2:202]\n",
    "\n",
    "# test attributes\n",
    "test_attributes = df_test.columns.values[1:201]\n",
    "\n",
    "# Distribution plot for kurtosis values per column in train attributes\n",
    "sns.distplot(df_train[train_attributes].kurtosis(axis = 0), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for kurtosis values per column in test attributes\n",
    "sns.distplot(df_test[test_attributes].kurtosis(axis = 0), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Kurtosis Values per Column in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of kurtosis Values per row in train and test dataset\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Distribution plot for kurtosis values per row in train attributes\n",
    "sns.distplot(df_train[train_attributes].kurtosis(axis = 1), color = 'red', kde = True, bins = 150, label = 'train')\n",
    "\n",
    "# Distribution plot for kurtosis values per row in test attributes\n",
    "sns.distplot(df_test[test_attributes].kurtosis(axis = 1), color = 'blue', kde = True, bins = 150, label = 'test')\n",
    "\n",
    "plt.title('Distribution of Kurtosis Values per Row in Train and Test Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea52b2-7a45-4a29-9575-e84cf590252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value analysis%%time\n",
    "# find the missing value in train and test dataset\n",
    "train_missing = df_train.isnull().sum().sum()\n",
    "test_missing = df_test.isnull().sum().sum()\n",
    "\n",
    "print(\"MISSING VALUES IN TRAIN DATASET : \",train_missing)\n",
    "print(\"MISSING VALUES IN TEST DATASET : \",test_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e2072-fb78-40a0-be8a-1832abdc14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation - No missing value is present in both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcaf490-332d-4407-b77e-5273cb6256d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326071a7-2c92-4876-afe9-cf81ab5ce240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# correlation in train attribute\n",
    "train_attributes  =df_train.columns.values[2:202]\n",
    "train_correlation = df_train[train_attributes].corr().abs().unstack().sort_values(kind = 'quicksort').reset_index()\n",
    "train_correlation = train_correlation[train_correlation['level_0'] != train_correlation['level_1']]\n",
    "print(train_correlation.head(10))\n",
    "print(train_correlation.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a64690-a087-44c3-8f43-b28c32f83d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# correlation in test attribute\n",
    "test_attributes  =df_test.columns.values[2:202]\n",
    "test_correlation = df_test[test_attributes].corr().abs().unstack().sort_values(kind = 'quicksort').reset_index()\n",
    "test_correlation = test_correlation[test_correlation['level_0'] != test_correlation['level_1']]\n",
    "print(test_correlation.head(10))\n",
    "print(test_correlation.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3a5da-1a2d-4eaa-9916-4241e4321b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obersvation - correlation amongst the train and the test attributes are very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f7a18-d10f-42af-888d-442237ecafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot for train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e23551-ab88-4d25-ab16-87414cdbf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correlation = df_train[train_attributes].corr()\n",
    "train_correlation = train_correlation.values.flatten()\n",
    "train_correlation = train_correlation[train_correlation != 1]\n",
    "\n",
    "test_correlation = df_test[test_attributes].corr()\n",
    "test_correlation = test_correlation.values.flatten()\n",
    "test_correlation = test_correlation[test_correlation != 1]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.distplot(train_correlation, color = 'blue', label = 'train')\n",
    "sns.distplot(test_correlation, color = 'red', label = 'test')\n",
    "plt.xlabel(\"CORRELATION VALUES FOUND IN TRAN AND TEST DATA\")\n",
    "plt.ylabel(\"DENSITY\")\n",
    "plt.title(\"CORRELATION VALUES IN TRAIN AND TEST DATA\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ad8bd-ba1a-4938-a772-0618b5d63ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation values found in train and test data are very small, its completely visible from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116905e-2b87-4c4a-b944-f80e8062aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering - performing feature engineering by using permutations importance - partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a242efe-ec23-47b4-a8c9-d8a3b99136cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing data\n",
    "x = df_train.drop(columns = ['ID_code', 'target'], axis = 1)\n",
    "test = df_test.drop(columns = ['ID_code'], axis = 1)\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d605b77-5750-4298-8782-16d7aa4b3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple model to find the features which are more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3582d-21a1-4353-881c-98865eac3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data\n",
    "x_train, y_train, x_test, y_test = train_test_split(x, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b041d5-cf74-41bf-a59c-e64623f0fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd45226-0d11-4927-a3bc-442a6a356036",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:len(y_train)]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf867e5-ae76-467e-857e-02b2a5beaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:10])  # Inspect first 10 values\n",
    "print(y_train.dtypes)  # Check the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cebf25-a40c-4540-bdb6-f2bc1e0b18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5  # Example threshold value\n",
    "y_train = (y_train > threshold).astype(int)  # Convert to binary classes (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7eea8b-7399-476e-a245-b480b55026a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "\n",
    "# fitting the model\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f277e3-dee0-4b1c-83ac-12c2beafd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating weights and observing some important features via using eli5 library. eli5 is a python library which helps to debug machine learning classifiers and explain their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699773b2-a91f-47c6-8769-ab49a6718a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Compute permutation importance\n",
    "result = permutation_importance(rf_model, x_train, y_train, scoring='accuracy')\n",
    "\n",
    "# Visualize results\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.barh(range(x_train.shape[1]), result.importances_mean[sorted_idx], align='center')\n",
    "plt.yticks(range(x_train.shape[1]), [x_train.columns[i] for i in sorted_idx])\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Feature Importance via Permutation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4312f2-9ea9-4ff5-96b2-8b90773ae4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation - features having highest to lowest importance is in descending order as show in the prediction. Features show in green having highe positive impact on prediction and features having zero impact on the color.\n",
    "# partial dependence plots - pdp gives a graphical depiction marginal effect of a variable on a class probably or classification. it shows how a feature effects predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d4a7c-a914-42b3-960d-08866665acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling of imbalanced data - multiple approaches can be used for dealing with it.\n",
    "# 1 change of performance matrix\n",
    "# 2 oversample minority class\n",
    "# 3 undersample majority class\n",
    "# 4 SMOTE(synthetic minority oversampling techniques)\n",
    "# 5 change of algorithm\n",
    "\n",
    "# logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815964d1-8937-407a-9d77-d8a6ac575577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sppliting the data with stratified k fold cross validator\n",
    "# traing data\n",
    "X = df_train.drop(['ID_code', 'target'], axis = 1)\n",
    "Y = df_train['target']\n",
    "\n",
    "# stratified k fold cross validator\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "for train_index, valid_index in skf.split(X,Y):\n",
    "    x_train, x_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = Y.iloc[train_index], Y.iloc[valid_index]\n",
    "\n",
    "print(\"SHAPE OF x_train : \",x_train.shape)\n",
    "print(\"SHAPE OF x_valid : \",x_valid.shape)\n",
    "print(\"SHAPE OF y_train : \",y_train.shape)\n",
    "print(\"SHAPE OF y_valid : \",y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdedbf-c34e-44ad-abba-2f2369dbd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model = LogisticRegression(random_state = 42)\n",
    "# fiiting the model\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91334e26-f7b6-4afd-abfc-4999538202a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the model\n",
    "lr_score = lr_model.score(x_train, y_train)\n",
    "print(\"ACCURACY OF THE lr_model : \", lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24a764-ba49-4d85-92c0-d39d18aa0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# cross validation prediction of the lr_model\n",
    "cv_predict = cross_val_predict(lr_model, x_valid, y_valid, cv = 5)\n",
    "# cross validation score\n",
    "cv_score = cross_val_score(lr_model, x_valid, y_valid, cv = 5)\n",
    "print(\"CROSS VALIDATION SCORE : \", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90861d19-f939-48b7-a737-d298090054be",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(cv_predict, return_counts = True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ea498-dd7f-41db-969b-239a97e85170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we wont be using accuracy as the performance metric because we cant apply it on an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e1d36-da60-4120-9c0b-6b92c1ffba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220159e-02b3-46ff-b495-427440f19c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_valid, cv_predict)\n",
    "cm = pd.crosstab(y_valid, cv_predict)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f29a6-6b3b-4d9c-8dc2-5efb95fc95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obersvation - on comparing roc_auc_score and model accuracy, model is not perfoming on the imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df81e0-7a6c-497e-8f43-a4d865b7c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_valid, cv_predict)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.title('RECEIVER OPERATING CHARACTERISTIC (ROC)')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='ROC (area = %0.3f)' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')  # Dashed diagonal line\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('RECALL (TRUE POSITIVE RATE)')\n",
    "plt.xlabel('FALSE POSITIVE RATE')\n",
    "plt.show()\n",
    "\n",
    "# Print AUC\n",
    "print('AUC :', roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d82729-d9c3-4dbf-a6ee-3798de6dd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "classification_scores = classification_report(y_valid, cv_predict)\n",
    "print(classification_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4693bb3-ecba-4c35-82e5-50496df670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obervation - as we see that f1 score is high for the customer who will not make a transaction compare to those who will make a transaction, so we are going to change the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45e558-6300-4408-9d81-007c61fb93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct syntax for dropping a column\n",
    "x_test = df_test.drop('ID_code', axis=1)\n",
    "\n",
    "# Predict on the test dataset\n",
    "lr_pred = lr_model.predict(x_test)\n",
    "\n",
    "# Print predictions\n",
    "print(lr_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821a140-fe1f-4182-81cb-b6c174dd7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type markdown and latex a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199ce47-4683-4f24-9f5f-704dd2ba5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample minority class\n",
    "# Oversample Minority Class\n",
    "\n",
    "# • Adding more copies of minority class\n",
    "\n",
    "# It can be a good option we don't have that much large data to work\n",
    "\n",
    "# • Drawback of this process is that we are adding information which may lead to overfitting or poor performance on test data.\n",
    "# Undersample Majority Class\n",
    "\n",
    "# • Removing some copies of majority class\n",
    "\n",
    "# • It can be a very good option if we have very large amount of data say in millions to work.\n",
    "# Drawback of this process is we are removing some valuable information, this can lead to underfitting and poor perfromance on test data.\n",
    "\n",
    "# As per the drawbacks of both the model we will use SMOTE (Synthetic Minority Oversampling Technique) that is more better than above.\n",
    "\n",
    "# SMOTE (Synthetic Minority Oversampling Technique) - This is a statistical technique for increasing the number of cases in your dataset in a b\n",
    "\n",
    "# uses a nearest neighbours algorithm to generate new and synthetic data to use for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7eda6-3652-4af3-8fed-f20a12246db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "sm = SMOTE(random_state=42, sampling_strategy=1.0)\n",
    "\n",
    "# Generating synthetic datapoints for training and validation sets\n",
    "x_smote, y_smote = sm.fit_resample(x_train, y_train)\n",
    "x_smote_v, y_smote_v = sm.fit_resample(x_valid, y_valid)\n",
    "\n",
    "print(\"Shape of x_smote:\", x_smote.shape)\n",
    "print(\"Shape of y_smote:\", y_smote.shape)\n",
    "print(\"Shape of x_smote_v:\", x_smote_v.shape)\n",
    "print(\"Shape of y_smote_v:\", y_smote_v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f8025-8779-4a4b-b6b4-30b178c8e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building logistic regression model on synthetic datapoinhts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d00a57-376e-412e-95df-10194ef8ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# logistic regression model for SMOTE\n",
    "smote = LogisticRegression(random_state = 42)\n",
    "# fitting the smote model\n",
    "smote.fit(x_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9860fc-32c9-46ed-8118-e5269cfecdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21636a1a-0e87-4952-b982-4f44d642045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of the model\n",
    "smote_score = smote.score(x_smote,y_smote)\n",
    "print(\"ACCURACY OF THE SMOTE_MODEL : \", smote_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edde07-50c2-477b-a0ae-9c0899f4d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# cross validation prediction for smote\n",
    "cv_pred = cross_val_predict(smote, x_smote_v, y_smote_v, cv = 5)\n",
    "# cross validation score\n",
    "cv_score = cross_val_score(smote, x_smote_v, y_smote_v, cv = 5)\n",
    "print(\"CROSS VALIDATION SCORE : \", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180046b-42bc-4df9-8e03-6f5f38b5ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_smote_v, cv_pred)\n",
    "cm = pd.crosstab(y_smote_v, cv_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed8161-eb71-4d36-83fb-31ef91323d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc auc score\n",
    "roc_score = roc_auc_score(y_smote_v, cv_pred)\n",
    "print(\"ROC SCORE : \", roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc9b30-6c49-4c0e-943a-0126ced66046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure `cv_pred` contains predicted probabilities\n",
    "# cv_pred_prob = model.predict_proba(x_smote_v)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_smote_v, cv_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.title('RECEIVER OPERATING CHARACTERISTIC (ROC)')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='ROC (area = %0.3f)' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')  # Dashed diagonal line\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('RECALL (TRUE POSITIVE RATE)')\n",
    "plt.xlabel('FALSE POSITIVE RATE')\n",
    "plt.show()\n",
    "\n",
    "# Print AUC\n",
    "print('AUC:', roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2591d45-ea73-46f8-99b8-2b57453e5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954b791-e331-47c3-b91e-0cf6c700b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = classification_report(y_smote_v, cv_pred)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b9ca0-9cc3-4b48-a699-cb6d178e249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can observe that theb f1 score is high for the customer who didnt make the transaction as well as the customer who made the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0579f8-003d-44fa-a58a-c6701a5b728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a004013-593b-4f27-9a00-90fec38b56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predicting the model\n",
    "x_test = df_test.drop(['ID_code'], axis = 1)\n",
    "smote_pred = smote.predict(x_test)\n",
    "print(smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909bb1e-faa3-476b-a2b3-2fb806231a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation - we can observe that smote model is performing better than simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2d1d7-f7ca-4473-9cdb-1ba86d6a6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light GBM - it is a gradient boosting framework that uses the time based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f97fd0-4fa4-429c-9104-300e1ad520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainging data\n",
    "lgb_train = lgb.Dataset(x_train, label = y_train)\n",
    "# validatng data\n",
    "lgb_valid = lgb.Dataset(x_valid, label = y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed901339-446f-4a5a-a3e4-323956a38df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the hyperparameter by tuning of differnet parameters\n",
    "params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'max_depth' : -1,\n",
    "    'objective' : 'binary',\n",
    "    'boost_from_average' : False,\n",
    "    'nthread' : 20,\n",
    "    'metric' : 'auc',\n",
    "    'num_leaves' : 50,\n",
    "    'learning_rate' : 0.01,\n",
    "    'max_bin' : 100,\n",
    "    'subsample for bin' : 100,\n",
    "    'subsample' : 1,\n",
    "    'subsample_freq' : 1,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'bagging_fraction' : 0.5,\n",
    "    'bagging_freq' : 5,\n",
    "    'feature_fraction' : 0.08,\n",
    "    'min_split_gain' : 0.45,\n",
    "    'min_child_weight' : 1,\n",
    "    'min_child_samples' : 5,\n",
    "    'is_unbalanced' : True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147108c-ade1-4f39-8094-1823779c44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Prepare the datasets\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_valid = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "num_rounds = 10000\n",
    "lgbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=num_rounds,\n",
    "    valid_sets=[lgb_train, lgb_valid],  # Specify training and validation datasets\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=5000),  # Early stopping\n",
    "        lgb.log_evaluation(period=1000)  # Log evaluation metrics every 1000 rounds\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the model\n",
    "print(lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424b26d-0149-42ea-991a-8800b40f7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop(['ID_code'], axis = 1)\n",
    "# predict the model\n",
    "# #probability predictions\n",
    "# Predict without specifying iterations\n",
    "lgbm_predict_prob = lgbm.predict(x_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "lgbm_predict = np.where(lgbm_predict_prob > 0.5, 1, 0)\n",
    "\n",
    "print(lgbm_predict_prob)\n",
    "print(lgbm_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ec198-0a35-4f18-aa49-9ddf4dd871b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014682d-2302-414f-bb1c-b27af79a5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgbm, max_num_features = 50, importance_type = \"split\", figsize = (20,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4223e64-0ffc-4a01-be56-bf63388b73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final submission\n",
    "df_sub = pd.DataFrame({'ID_code' : df_test['ID_code'].values})\n",
    "df_sub['lgbm_predict_prob'] = lgbm_predict_prob\n",
    "df_sub['lgbm_predict'] = lgbm_predict\n",
    "df_sub.to_csv('SUBMISSION.csv', index = False)\n",
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
